{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707c296-a683-4c45-99f9-320407634371",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --quiet langchain-core langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98b3e1-ab8c-4a93-b0a9-e1da419c773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "api_key = \"<key>\"\n",
    "api_endpoint = \"https://<instance>.openai.azure.com/\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" \n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = api_key\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = api_endpoint\n",
    "\n",
    "model_name= \"gpt-4o\"\n",
    "api_version = '2024-12-01-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242e8ca-9f5f-4e93-ad6c-8126770569d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_file = \"prompts/prompt_lang_parameter.txt\"\n",
    "example_file = \"prompts/example_greek.txt\"\n",
    "example_patient_text_file = \"prompts/example_file_greek.txt\"\n",
    "example_entities_file = \"prompts/example_entities_greek.txt\"\n",
    "lang = \"Greek\"\n",
    "\n",
    "dev_dataset_path = 'elcardiocc/dev_dataset.tsv'\n",
    "predicted_results_path = f'predictions/elcardiocc_dev_dataset_full_linking_{model_name}_zero.tsv'\n",
    "predicted_entities_path = f'predictions/elcardio_predicted_entities_full_linking_{model_name}_zero.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d756e-ad84-40ca-8423-47cd48810167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131cc46-18b8-4e36-9ad2-d3a80c3941e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "prompt, examples, patient_text = '', '', ''\n",
    "ner_entities = []\n",
    "delimiter = '[TERM]'\n",
    "delimiter_name = \"special tokens\"\n",
    "\n",
    "with open(prompt_file, 'r', encoding=\"utf-8\") as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "with open(example_file, 'r', encoding=\"utf-8\") as file:\n",
    "    examples = file.read().replace('{delimiter}', delimiter)\n",
    "\n",
    "examples = \"\" # zero shot\n",
    "\n",
    "with open(example_patient_text_file, 'r', encoding=\"utf-8\") as file:\n",
    "    patient_text = file.read()\n",
    "\n",
    "with open(example_entities_file, 'r', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    ner_entities = literal_eval(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02744d-c5f8-4793-824a-5054c81e0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(text, entities):\n",
    "    text_parts = []\n",
    "    last_entity_end = 0\n",
    "    for entity in entities:\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        text_parts.append(text[last_entity_end:start])\n",
    "        text_parts.append(f\"{delimiter}{text[start:end]}{delimiter}\")\n",
    "        last_entity_end = end\n",
    "\n",
    "    text_parts.append(text[last_entity_end:])\n",
    "    return \"\".join(text_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf053f0-8e89-4493-8bd3-2a004a31abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_text(patient_text, ner_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd687ed-8946-4922-8842-2430be87fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "        prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad5c8f-e55f-4104-89e1-a33de8d76efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.globals import set_verbose\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "if os.environ[\"OPENAI_API_KEY\"] == '': #use azure deployment\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=model_name,\n",
    "        api_version=api_version,\n",
    "        temperature=0.5,\n",
    "        max_tokens=6000,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    ).with_structured_output(method=\"json_mode\")\n",
    "else:    \n",
    "    llm = ChatOpenAI(\n",
    "        model=model_name,\n",
    "        temperature=0.5,\n",
    "        max_tokens=6000,\n",
    "        timeout=None,\n",
    "        max_retries=2\n",
    "    ).with_structured_output(method=\"json_mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d1559-cb48-4f3c-b2a5-b811f32c0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_text = prepare_text(patient_text, ner_entities)\n",
    "prompt = tagging_prompt.invoke({\"clinical_text\": prep_text, \"language\": lang, \"language_lower\": lang.lower(), \"examples\": examples, \"delimiter\": delimiter, \"delimiter_name\": delimiter_name})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f910f5-2fc8-460e-9a41-8ded3f532f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217fe3a2-5e36-4947-bb68-979dadb42edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f36de-eb9e-42b4-914a-bea80cc9b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dev_dataset = pd.read_csv(dev_dataset_path, sep='\\t')\n",
    "dev_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b4cb8-c8d4-4e69-a5de-eea6a2f98d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "dev_dataset['annotations'] = dev_dataset['annotations'].apply(literal_eval)\n",
    "dev_dataset['response'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b81d1e-5bfb-4c8b-976e-f33068a2ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "for index, row in tqdm(dev_dataset.iterrows(), total=dev_dataset.shape[0]):\n",
    "    if row['response'] != '':\n",
    "        continue\n",
    "    text = row['text']\n",
    "    prep_text = prepare_text(text, row['annotations'])\n",
    "    prompt = tagging_prompt.invoke({\"clinical_text\": prep_text, \"language\": lang, \"language_lower\": lang.lower(), \"examples\": examples, \"delimiter\": delimiter, \"delimiter_name\": delimiter_name})\n",
    "    response = llm.invoke(prompt)\n",
    "    dev_dataset.at[index, 'response'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb8132-6778-4b67-8119-293737e697bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7524d0-8a99-43c7-a0c5-bb4f24deb6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset[dev_dataset['response']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df17f63-6182-4356-b1bb-53f68043ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset.to_csv(predicted_results_path, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465decc-43f0-4a7d-8b79-4bd9816a919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e649a-4092-4273-bd29-df077a03a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset['text'].iloc[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9062bb40-b305-4a30-9223-d47d34d8bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed457b-845c-4649-a893-b49c765b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurrences(term, text):\n",
    "    occurrences = []\n",
    "    i = 0\n",
    "    while True:\n",
    "    \tf = text.find(term, i)\n",
    "    \tif f==-1:\n",
    "    \t\tbreak\n",
    "    \toccurrences.append(f)\n",
    "    \ti = f+1\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b1e2a-394e-4b8c-aece-70d00331076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "lang_lower = lang.lower()\n",
    "entities_list = []\n",
    "last_end_index = 0\n",
    "\n",
    "for index, row in dev_dataset.iterrows():\n",
    "    if row['response'] == '':\n",
    "        continue\n",
    "        \n",
    "    ents = row['response']\n",
    "    text = row['text']\n",
    "    \n",
    "    keys = list(ents.keys())\n",
    "    if len(keys) > 1:\n",
    "        entities = [ row['response'] ]\n",
    "    else:\n",
    "        key = keys[0]\n",
    "        entities = row['response'][key]\n",
    "    entity_list = []\n",
    "    for ent in entities:\n",
    "        if not isinstance(ent, dict):\n",
    "            print(row['response'])\n",
    "            continue\n",
    "        term = ent[f'medical_term_{lang_lower}'].replace(delimiter, '') #strip if *\n",
    "        code = ent['icd10_code']\n",
    "\n",
    "        if term.upper() not in text.upper():\n",
    "            continue\n",
    "            \n",
    "        indices = [(m, m+len(term)) for m in get_occurrences(term.upper(), text.upper())]\n",
    "        for index in indices:\n",
    "            start, end = index\n",
    "            if term.upper() != text.upper()[start:end].upper():\n",
    "                print(term, text[start:end])\n",
    "            entity_list.append({\n",
    "                'filename': row['id'],\n",
    "                'ann_id': 'ICD',\n",
    "                'label': 'ICD',\n",
    "                'start_span': start,\n",
    "                'end_span': end,\n",
    "                'text': term,\n",
    "                'code': code #[0:3]\n",
    "            })\n",
    "        \n",
    "    entities_list.append(entity_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d5a70-a28f-4b3e-8f11-a8ee6198b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac8c04-4271-4c22-8533-57a478518ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = []\n",
    "for index, row in dev_dataset.iterrows():     \n",
    "    if row['response'] == '':\n",
    "        continue\n",
    "           \n",
    "    pred_list = entities_list[index]\n",
    "    true_list = row['annotations']\n",
    "    text = row['text']\n",
    "    code_indices = ['' for i in range(0, len(text))]\n",
    "    \n",
    "    for entity in pred_list:\n",
    "        start = entity['start_span']\n",
    "        end = entity['end_span']\n",
    "        for i in range(start, end):\n",
    "            code_indices[i] = entity['code']\n",
    "\n",
    "    merged_pred_list = []\n",
    "    for entity in true_list:\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        for i in range(start, end):\n",
    "            if code_indices[i] != '':\n",
    "                entity['filename'] = row['id']\n",
    "                entity['ann_id'] = 'ICD'\n",
    "                entity['label'] = 'ICD' # 'ICD'\n",
    "                entity['text'] = text[start:end]\n",
    "                entity['code'] = code_indices[i]                \n",
    "                merged_pred_list.append(entity)\n",
    "                break\n",
    "\n",
    "    merged_list.append(merged_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ffc1a-be47-4bec-bc63-b8f4fcab427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_entities_list = pd.DataFrame.from_records(sum(merged_list, []))\n",
    "df_entities_list.drop_duplicates(inplace=True)\n",
    "df_entities_list['code'] =  df_entities_list['code'].apply(str).apply(lambda x: x[0:3])\n",
    "df_entities_list = df_entities_list.rename(columns={'start':'start_span', 'end': 'end_span'})\n",
    "df_entities_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0697d0-8931-49ce-afcd-f3cdce78840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities_list[['filename','ann_id','label','start_span','end_span','text','code']].to_csv(predicted_entities_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f051c5a-c0a3-45bc-a47a-57b9acfab765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27dbb4-ee72-4c9a-8493-f4f2af89e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e26e42-a680-49bb-9b8d-ca9fef188c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.read_csv('elcardiocc/train_subtask2_direct_match_predictions.tsv', sep='\\t', keep_default_na=False)\n",
    "df_dict['filename']=df_dict['id']\n",
    "df_dict['start_span']=df_dict['start']\n",
    "df_dict['end_span']=df_dict['end']\n",
    "df_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e0d58-ab84-477e-9672-d9461a019acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_dict.iterrows():\n",
    "    if row['predicted_code'] != '':\n",
    "        continue\n",
    "    filter_start = df_entities_list['start_span'] == int(row['start_span'])\n",
    "    filter_end = df_entities_list['end_span'] == int(row['end_span'])\n",
    "    filter_file = df_entities_list['filename'] == int(row['filename'])\n",
    "    df_filter = df_entities_list[filter_start & filter_end & filter_file]\n",
    "    if df_filter.shape[0] > 0:\n",
    "        gpt_code = df_filter.iloc[0]['code']\n",
    "        df_dict.at[index, 'predicted_code'] = gpt_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2aebe6-12e3-4a84-901d-2e5b39ab7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83253c15-2a7f-4f83-9e7a-5fdbc4783b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict['ann_id']='ICD'\n",
    "df_dict['label']='ICD'\n",
    "df_dict['text']=df_dict['mention']\n",
    "df_dict = df_dict.rename(columns={'code':'true_code'})\n",
    "df_dict[['filename','ann_id','label','start_span','end_span','text','predicted_code']].rename(columns={'predicted_code':'code'}).to_csv(f'{predicted_entities_path}_dict_cat.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d52e0-0a10-4fe1-b381-60823d4a8042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
